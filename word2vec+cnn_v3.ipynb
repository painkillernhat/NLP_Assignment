{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22959,"status":"ok","timestamp":1653989276555,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"sQic7KJRaSP6","outputId":"ecec867d-34a0-4c95-d5d8-d51e999e0ff3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":97,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4639,"status":"ok","timestamp":1653989252196,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"aoVjFKmOZMZ8","outputId":"bcd119ff-e091-4cf5-ca96-45e131211e1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: pyvi in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (0.1.1)\n","Requirement already satisfied: keras in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (2.15.0)\n","Requirement already satisfied: gensim in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (4.3.2)\n","Requirement already satisfied: scikit-learn in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from pyvi) (1.0.2)\n","Requirement already satisfied: sklearn-crfsuite in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from pyvi) (0.3.6)\n","Requirement already satisfied: numpy>=1.18.5 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from gensim) (1.23.5)\n","Requirement already satisfied: scipy>=1.7.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from gensim) (1.9.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from gensim) (6.4.0)\n","Requirement already satisfied: joblib>=0.11 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from scikit-learn->pyvi) (1.3.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from scikit-learn->pyvi) (3.2.0)\n","Requirement already satisfied: python-crfsuite>=0.8.3 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from sklearn-crfsuite->pyvi) (0.9.9)\n","Requirement already satisfied: six in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n","Requirement already satisfied: tabulate in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from sklearn-crfsuite->pyvi) (4.64.1)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: keras in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (2.15.0)\n","Collecting keras\n","  Using cached keras-3.0.0-py3-none-any.whl.metadata (5.3 kB)\n","Requirement already satisfied: tensorflow in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (2.15.0)\n","Requirement already satisfied: absl-py in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from keras) (1.4.0)\n","Requirement already satisfied: numpy in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from keras) (1.23.5)\n","Collecting rich (from keras)\n","  Using cached rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n","Collecting namex (from keras)\n","  Using cached namex-0.0.7-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: h5py in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from keras) (3.9.0)\n","Collecting dm-tree (from keras)\n","  Using cached dm_tree-0.1.8-cp39-cp39-macosx_11_0_arm64.whl (110 kB)\n","Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.23.4)\n","Requirement already satisfied: setuptools in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (69.0.2)\n","Requirement already satisfied: six>=1.12.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.34.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.56.2)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.22.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.3.6)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (4.9)\n","Requirement already satisfied: urllib3<2.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.26.16)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (6.8.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.3)\n","Requirement already satisfied: zipp>=0.5 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.16.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.2.2)\n","Collecting markdown-it-py>=2.2.0 (from rich->keras)\n","  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/thunguyen/Library/Python/3.9/lib/python/site-packages (from rich->keras) (2.16.1)\n","Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n","  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Defaulting to user installation because normal site-packages is not writeable\n","\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-text==2.13.* (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-text==2.13.*\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip3 install pyvi keras gensim\n","!pip3 install --upgrade keras tensorflow\n","!pip3 install \"tensorflow-text==2.13.*\""]},{"cell_type":"code","execution_count":98,"metadata":{"id":"8TFX7wSAmg9y"},"outputs":[],"source":["from __future__ import division, print_function\n","from gensim import models\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers import Dense, Dropout, Reshape, Flatten, concatenate, Input, Conv1D, GlobalMaxPooling1D, Embedding\n","# from keras.layers.recurrent import LSTM\n","from keras.models import Sequential\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Model\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","import os\n","import re\n","from string import digits\n","from collections import Counter\n","from pyvi import ViTokenizer"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"a7lMy03omg93","scrolled":true},"outputs":[],"source":["data_train = pd.read_csv(\"./vlsp_sentiment_train.csv\", sep='\\t')\n","data_train.columns =['Class', 'Data']\n","data_test = pd.read_csv(\"./vlsp_sentiment_test.csv\", sep='\\t')\n","data_test.columns =['Class', 'Data']"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Class</th>\n","      <th>Data</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1</td>\n","      <td>Mình đã dùng anywhere thế hệ đầu, quả là đầy t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-1</td>\n","      <td>Quan tâm nhất là độ trễ có cao không, dùng thi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1</td>\n","      <td>dag xài con cùi bắp 98k....pin trâu, mỗi tội đ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-1</td>\n","      <td>logitech chắc hàng phải tiền triệu trở lên dùn...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1</td>\n","      <td>Đang xài con m175 cùi mía , nhà xài nhiều chuộ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Class                                               Data\n","0     -1  Mình đã dùng anywhere thế hệ đầu, quả là đầy t...\n","1     -1  Quan tâm nhất là độ trễ có cao không, dùng thi...\n","2     -1  dag xài con cùi bắp 98k....pin trâu, mỗi tội đ...\n","3     -1  logitech chắc hàng phải tiền triệu trở lên dùn...\n","4     -1  Đang xài con m175 cùi mía , nhà xài nhiều chuộ..."]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["data_train.head()"]},{"cell_type":"code","execution_count":101,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":944,"status":"ok","timestamp":1653989301990,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"4HR1jAzImg94","outputId":"8e324c8c-0dbb-4a69-aeff-b03e40766c7e"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5100, 2)\n","(1050, 2)\n"]}],"source":["print(data_train.shape)\n","print(data_test.shape)"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"jvrbwPfZmg95"},"outputs":[],"source":["labels = data_train.iloc[:, 0].values\n","reviews = data_train.iloc[:, 1].values"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[],"source":["with open(\"./stopwords.txt\", \"r\", encoding=\"utf8\") as f:\n","    stopwords = f.read().splitlines()\n","\n","def remove_stop_words(text, stopwords):\n","    words = text.split()\n","    words = [word for word in words if word not in stopwords]\n","    text = ' '.join(words)\n","    return text"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"3HlbVeHimg95"},"outputs":[],"source":["encoded_labels = []\n","\n","for label in labels:\n","    if label == -1:\n","        encoded_labels.append([1,0,0])\n","    elif label == 0:\n","        encoded_labels.append([0,1,0])\n","    else:\n","        encoded_labels.append([0,0,1])\n","\n","encoded_labels = np.array(encoded_labels)  "]},{"cell_type":"code","execution_count":105,"metadata":{"id":"Lm4OCwxXmg96"},"outputs":[],"source":["reviews_processed = []\n","unlabeled_processed = [] \n","for review in reviews:\n","    review_cool_one = ''.join([char for char in review if char not in string.digits])\n","    # review_cool_one = remove_stop_words(review_cool_one, stopwords)\n","    reviews_processed.append(review_cool_one)"]},{"cell_type":"code","execution_count":106,"metadata":{"id":"nW2OZgkgmg97"},"outputs":[],"source":["#Use PyVi for Vietnamese word tokenizer\n","word_reviews = []\n","all_words = []\n","for review in reviews_processed:\n","    review = ViTokenizer.tokenize(review.lower())\n","    word_reviews.append(review.split())\n","   "]},{"cell_type":"code","execution_count":107,"metadata":{"id":"pTb0MeDRmg98"},"outputs":[],"source":["EMBEDDING_DIM = 400 # how big is each word vector\n","MAX_VOCAB_SIZE = 10000 # how many unique words to use (i.e num rows in embedding vector)\n","MAX_SEQUENCE_LENGTH = 300 # max number of words in a comment to use"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"jW-7mKtWmg9-"},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","execution_count":109,"metadata":{"id":"-BHpPSLTmg9_"},"outputs":[],"source":["tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, lower=True, char_level=False)\n","tokenizer.fit_on_texts(word_reviews)\n","sequences_train = tokenizer.texts_to_sequences(word_reviews)\n","word_index = tokenizer.word_index\n"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"LlV3M2dimg9_"},"outputs":[],"source":["data = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH)\n","labels = encoded_labels"]},{"cell_type":"code","execution_count":111,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1653989306259,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"4dl9VZ3Rmg-A","outputId":"0d43e170-e903-4d5b-f3ec-18a8b911d072"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X train and X validation tensor: (5100, 300)\n","Shape of label train and validation tensor: (5100, 3)\n"]}],"source":["print('Shape of X train and X validation tensor:',data.shape)\n","print('Shape of label train and validation tensor:', labels.shape)"]},{"cell_type":"code","execution_count":112,"metadata":{"id":"-KKSjJdJmg-A"},"outputs":[],"source":["import gensim\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","\n","word_vectors = KeyedVectors.load_word2vec_format(\"./vi-model-CBOW.bin\", binary=True)\n","\n","\n","vocabulary_size=min(len(word_index)+1,MAX_VOCAB_SIZE)\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    if i>=MAX_VOCAB_SIZE:\n","        continue\n","    try:\n","        embedding_vector = word_vectors[word]\n","        embedding_matrix[i] = embedding_vector\n","    except KeyError:\n","        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n","\n","del(word_vectors)\n","\n","from keras.layers import Embedding\n","embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            trainable=True)"]},{"cell_type":"code","execution_count":113,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1653989417080,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"njBANdn5mg-B","outputId":"24647910-9144-4987-83a2-fe64e64a04ac"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n","WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model_6\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_11 (InputLayer)       [(None, 300)]                0         []                            \n","                                                                                                  \n"," embedding_5 (Embedding)     (None, 300, 400)             3167600   ['input_11[0][0]']            \n","                                                                                                  \n"," conv1d_19 (Conv1D)          (None, 298, 100)             120100    ['embedding_5[0][0]']         \n","                                                                                                  \n"," conv1d_20 (Conv1D)          (None, 297, 100)             160100    ['embedding_5[0][0]']         \n","                                                                                                  \n"," conv1d_21 (Conv1D)          (None, 296, 100)             200100    ['embedding_5[0][0]']         \n","                                                                                                  \n"," global_max_pooling1d_4 (Gl  (None, 100)                  0         ['conv1d_19[0][0]']           \n"," obalMaxPooling1D)                                                                                \n","                                                                                                  \n"," global_max_pooling1d_5 (Gl  (None, 100)                  0         ['conv1d_20[0][0]']           \n"," obalMaxPooling1D)                                                                                \n","                                                                                                  \n"," global_max_pooling1d_6 (Gl  (None, 100)                  0         ['conv1d_21[0][0]']           \n"," obalMaxPooling1D)                                                                                \n","                                                                                                  \n"," concatenate_6 (Concatenate  (None, 300)                  0         ['global_max_pooling1d_4[0][0]\n"," )                                                                  ',                            \n","                                                                     'global_max_pooling1d_5[0][0]\n","                                                                    ',                            \n","                                                                     'global_max_pooling1d_6[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," dropout_6 (Dropout)         (None, 300)                  0         ['concatenate_6[0][0]']       \n","                                                                                                  \n"," dense_6 (Dense)             (None, 3)                    903       ['dropout_6[0][0]']           \n","                                                                                                  \n","==================================================================================================\n","Total params: 3648803 (13.92 MB)\n","Trainable params: 3648803 (13.92 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["from keras.models import Model\n","from keras.layers import *\n","from keras import regularizers\n","from tensorflow.keras.optimizers import Adam\n","\n","sequence_length = data.shape[1]\n","filter_sizes = [3,4,5]\n","num_filters = 100\n","drop = 0.5\n","\n","inputs = Input(shape=(sequence_length,))\n","embedding = Embedding(input_dim=vocabulary_size, output_dim=EMBEDDING_DIM, input_length=sequence_length)(inputs)\n","\n","conv_0 = Conv1D(num_filters, filter_sizes[0], activation='relu', kernel_regularizer=regularizers.l2(0.01))(embedding)\n","maxpool_0 = GlobalMaxPooling1D()(conv_0)\n","\n","conv_1 = Conv1D(num_filters, filter_sizes[1], activation='relu', kernel_regularizer=regularizers.l2(0.01))(embedding)\n","maxpool_1 = GlobalMaxPooling1D()(conv_1)\n","\n","conv_2 = Conv1D(num_filters, filter_sizes[2], activation='relu', kernel_regularizer=regularizers.l2(0.01))(embedding)\n","maxpool_2 = GlobalMaxPooling1D()(conv_2)\n","\n","merged_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2])\n","dropout = Dropout(drop)(merged_tensor)\n","output = Dense(units=3, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n","\n","model = Model(inputs, output)\n","\n","adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":114,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10375,"status":"ok","timestamp":1653989547863,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"Jn0dBlzjmg-D","outputId":"be7de957-bf78-4fff-bc31-b5e586f705fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","16/16 [==============================] - 13s 784ms/step - loss: 4.3601 - accuracy: 0.4522 - val_loss: 3.7530 - val_accuracy: 0.0000e+00\n","Epoch 2/10\n","16/16 [==============================] - 13s 808ms/step - loss: 2.2006 - accuracy: 0.6064 - val_loss: 2.3455 - val_accuracy: 0.0000e+00\n","Epoch 3/10\n","16/16 [==============================] - 13s 821ms/step - loss: 1.3519 - accuracy: 0.6544 - val_loss: 1.9357 - val_accuracy: 0.0000e+00\n","Epoch 4/10\n","16/16 [==============================] - 13s 835ms/step - loss: 1.0434 - accuracy: 0.6782 - val_loss: 1.8663 - val_accuracy: 0.0000e+00\n","Epoch 5/10\n","16/16 [==============================] - 13s 834ms/step - loss: 0.9011 - accuracy: 0.7042 - val_loss: 1.7912 - val_accuracy: 0.0000e+00\n","Epoch 6/10\n","16/16 [==============================] - 13s 842ms/step - loss: 0.8133 - accuracy: 0.7358 - val_loss: 1.7834 - val_accuracy: 0.0059\n","Epoch 7/10\n","16/16 [==============================] - 14s 867ms/step - loss: 0.7400 - accuracy: 0.7748 - val_loss: 1.7700 - val_accuracy: 0.0373\n","Epoch 8/10\n","16/16 [==============================] - 15s 926ms/step - loss: 0.6830 - accuracy: 0.8145 - val_loss: 1.8530 - val_accuracy: 0.0510\n","Epoch 9/10\n","16/16 [==============================] - 14s 871ms/step - loss: 0.6247 - accuracy: 0.8525 - val_loss: 1.9275 - val_accuracy: 0.0598\n","Epoch 10/10\n","16/16 [==============================] - 14s 870ms/step - loss: 0.5723 - accuracy: 0.8870 - val_loss: 2.0589 - val_accuracy: 0.0549\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x11b381af0>"]},"execution_count":114,"metadata":{},"output_type":"execute_result"}],"source":["early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n","callbacks_list = [early_stopping]\n","\n","model.fit(data, labels, validation_split=0.2,\n","          epochs=10, batch_size=256, callbacks=callbacks_list, shuffle=True)"]},{"cell_type":"code","execution_count":115,"metadata":{"id":"8XoN2UOamg-D"},"outputs":[],"source":["labels_test = data_test.iloc[:, 0].values\n","reviews_test = data_test.iloc[:, 1].values"]},{"cell_type":"code","execution_count":116,"metadata":{"id":"PwiYb3Ohmg-E"},"outputs":[],"source":["encoded_labels_test = []\n","\n","for label_test in labels_test:\n","    if label_test == -1:\n","        encoded_labels_test.append([1,0,0])\n","    elif label_test == 0:\n","        encoded_labels_test.append([0,1,0])\n","    else:\n","        encoded_labels_test.append([0,0,1])\n","\n","encoded_labels_test = np.array(encoded_labels_test)  "]},{"cell_type":"code","execution_count":117,"metadata":{"id":"E08tBw9img-E"},"outputs":[],"source":["reviews_processed_test = []\n","unlabeled_processed_test = [] \n","for review_test in reviews_test:\n","    review_cool_one = ''.join([char for char in review_test if char not in digits])\n","    # review_cool_one = remove_stop_words(review_cool_one, stopwords)\n","    reviews_processed_test.append(review_cool_one)"]},{"cell_type":"code","execution_count":118,"metadata":{"id":"OwgI9Xywmg-E"},"outputs":[],"source":["#Use PyVi for Vietnamese word tokenizer\n","word_reviews_test = []\n","all_words = []\n","for review_test in reviews_processed_test:\n","    review_test = ViTokenizer.tokenize(review_test.lower())\n","    word_reviews_test.append(review_test.split())"]},{"cell_type":"code","execution_count":119,"metadata":{"id":"p02GxCh6mg-F"},"outputs":[],"source":["sequences_test = tokenizer.texts_to_sequences(word_reviews_test)\n","data_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n","labels_test = encoded_labels_test"]},{"cell_type":"code","execution_count":120,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":534,"status":"ok","timestamp":1653989480441,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"jAqUMGInmg-F","outputId":"40acf056-b9c9-42ed-c767-423cc2054383"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X train and X validation tensor: (1050, 300)\n","Shape of label train and validation tensor: (1050, 3)\n"]}],"source":["print('Shape of X train and X validation tensor:',data_test.shape)\n","print('Shape of label train and validation tensor:', labels_test.shape)"]},{"cell_type":"code","execution_count":121,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":596,"status":"ok","timestamp":1653989548454,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"LKclttiOmg-F","outputId":"6abe8e2e-7ed4-439f-8899-e6b30a044758"},"outputs":[{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 1s 29ms/step - loss: 1.0589 - accuracy: 0.6181\n"]}],"source":["score = model.evaluate(data_test, labels_test)"]},{"cell_type":"code","execution_count":122,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":355,"status":"ok","timestamp":1653989552805,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"r31_uxxgmg-G","outputId":"2fb9d570-546b-4652-ca5f-5e6794fc6198"},"outputs":[{"name":"stdout","output_type":"stream","text":["loss: 105.89%\n","accuracy: 61.81%\n"]}],"source":["print(\"%s: %.2f%%\" % (model.metrics_names[0], score[0]*100))\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8O3z4IFmg-G"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"word2vec+cnn_v3.ipynb","provenance":[{"file_id":"1rFZZf9ECknkLNDv8so_kQNPhqain0RqJ","timestamp":1653989613942}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
